# ğŸš€ End-to-End Cloud Deployment of ML App (Task-05)

This project demonstrates a complete **end-to-end machine learning deployment workflow**, starting from model training to cloud deployment using **Docker and CI/CD**.

The application trains a simple ML model, exposes predictions via a **Flask REST API**, containerizes the app using **Docker**, and deploys it to the cloud using **Render** with **automatic redeployment on GitHub updates**.

---

## ğŸ“Œ Project Flow

```
Data â†’ ML Model â†’ Flask API â†’ Docker Container â†’ Cloud (Render) â†’ CI/CD
```

---

## ğŸ§  Tech Stack Used

- Python  
- scikit-learn  
- Flask  
- Docker  
- GitHub  
- Render (Cloud Deployment)  
- Play with Docker (Docker validation)  

---

## ğŸ“‚ Project Structure

```
VELSYNC_CCD_05/
â”‚
â”œâ”€â”€ app.py              # Flask API
â”œâ”€â”€ train_model.py      # ML model training script
â”œâ”€â”€ model.pkl           # Trained ML model
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ Dockerfile          # Docker configuration
â””â”€â”€ README.md           # Project documentation
```

---

## âš™ï¸ ML Model Details

- **Dataset**: Iris Dataset (scikit-learn)
- **Algorithm**: RandomForestClassifier
- **Purpose**: Classify iris flower species based on input features

---

## ğŸŒ API Endpoints

### ğŸ”¹ Health Check
```
GET /health
```

**Response:**
```json
{
  "status": "API is running"
}
```

---

### ğŸ”¹ Prediction Endpoint
```
POST /predict
```

**Request Body:**
```json
{
  "features": [5.1, 3.5, 1.4, 0.2]
}
```

**Response:**
```json
{
  "prediction": 0
}
```

---

## ğŸ³ Dockerization

- The Flask ML application is containerized using Docker
- Dockerfile handles dependency installation and app execution
- Container exposes port **5000**

---

## â˜ï¸ Cloud Deployment (Render)

- Dockerized application deployed to **Render**
- Render builds Docker image directly from GitHub repository
- **CI/CD enabled**: Any push to GitHub triggers auto-redeployment

ğŸ”— **Live Application URL**
```
https://velsync-ccd-05.onrender.com/health
```

---

## ğŸ“¸ Screenshots

> Create a folder named `screenshots/` in the repository and add the following images.

### 1ï¸âƒ£ Docker Container Running (Play with Docker)
![Docker Container Running](output1.png)

### 2ï¸âƒ£ Health Endpoint Tested Using curl
![Health Check Curl](output3.png)

### 3ï¸âƒ£ Render Deployment Logs (Service Live)
![Render Logs](output2.png)

### 4ï¸âƒ£ Live Cloud Health Check
![Live Health API](output4.png)

---

## ğŸ” CI/CD Workflow

1. Code pushed to GitHub  
2. Render detects repository changes  
3. Docker image rebuilt automatically  
4. Application redeployed without manual intervention  

---

## âœ… Final Outcome

âœ” ML model trained  
âœ” Flask API created  
âœ” Docker container built  
âœ” Docker validated using Play with Docker  
âœ” Cloud deployment completed  
âœ” Public live URL generated  
âœ” CI/CD pipeline enabled  

---

## ğŸ“Œ Conclusion

This project successfully demonstrates an **end-to-end ML cloud deployment pipeline**, integrating machine learning, backend development, containerization, and cloud DevOps practices.

It reflects real-world deployment workflows used in modern production environments.

---

## ğŸ‘©â€ğŸ’» Author

**Clara**
